{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32fe3c6d-09ea-4c0e-81f7-3c8454d05e77",
   "metadata": {},
   "source": [
    "# PS3: Kernelized Support Vector Machines (kSVMs)\n",
    "In this problem set, we will experiment with a kernel Support Vector Machine (SVM) to classify challenging non-linearly separable datasets taken from the literature. In particular, we'll look at a kernelized version of the $\\nu$-soft-margin support vector machine. If these terms are unfamiliar, [check out the L5c notes](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-5/L5c/docs/Notes.pdf) and the [this review](https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf).\n",
    "\n",
    "### Theory: Support Vector Machine (SVM)\n",
    "Suppose we have dataset $\\mathcal{D} = \\{(\\hat{\\mathbf{x}}_{i}, y_{i}) \\mid i = 1,2,\\dots,n\\}$, where $\\hat{\\mathbf{x}}_i \\in \\mathbb{R}^p$ is an _augmented_ feature vector ($m$ features with additional `1` to model the bias on the end of the vector) and $y_i \\in \\{-1, 1\\}$ is the corresponding class label. The goal of an SVM (for binary classification tasks) is to find the hyperplane $\\mathcal{H}(\\hat{\\mathbf{x}}) = \\{\\hat{\\mathbf{x}} \\mid \\left<\\hat{\\mathbf{x}},\\theta\\right> = 0\\}$ that separates the data points into two classes (those points above the hyperplane, and those points below the hyperplane), where $\\theta \\in \\mathbb{R}^{p}$ ($p=m+1$) is the normal vector to the hyperplane, or the parameters of the model that we need to estimate.\n",
    "\n",
    "#### $\\nu$-Soft margin support vector machine\n",
    "Today, we'll use a variant of the soft-margin support vector machine developed by Scholkopf et al. called the $\\nu$-support vector classifier:\n",
    "* [Scholkopf B, Smola AJ, Williamson RC, Bartlett PL. New support vector algorithms. Neural Comput. 2000 May;12(5):1207-45. doi: 10.1162/089976600300015565. PMID: 10905814.](https://pubmed.ncbi.nlm.nih.gov/10905814/)\n",
    "\n",
    "This approach introduces a new parameter $\\nu\\in(0,1]$, where $\\nu$ approximates the upper bound on the number of training mistakes. It also replaces the cost coefficient $C$\n",
    "with a model of its value.  In this variant, the training problem (for $l$ training examples) is defined as: \n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\theta}\\quad & \\frac{1}{2}\\lVert{\\theta}\\rVert_{2}^{2} -\\nu\\rho+ \\frac{1}{l}\\sum_{i=1}^{n}\\xi_{i}\\\\\n",
    "    \\text{subject to}\\quad & y_{i}\\left<\\phi(\\hat{\\mathbf{x}}_{i}),\\theta\\right> \\geq \\rho - \\xi_{i}\\quad\\forall i\\\\\n",
    "    & \\xi_{i} \\geq 0\\quad\\forall{i}\\quad\\rho\\geq{0}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\xi_{i}$ is a _slack variable_, that quantifies the cost of a classification mistake, and $\\nu\\in(0,1]$ is a user-defined hyperparameter. Notice, that $C\\equiv{1/l}$ in this variant, thus, as $l\\to\\infty$ then $C\\to{0}$. Finally, notice that we are applying the transformation $\\phi:\\mathbb{R}^{p}\\to\\mathbb{R}^{q}$ where $q>p$ to the input feature vector. This is done _implcitly_ when we select a [kernel function](https://en.wikipedia.org/wiki/Kernel_method).\n",
    "\n",
    "### Tasks\n",
    "Before you start, execute the `Run All Cells` command to check if you have any code or setup issues. Code issues, post them [to Ed Discussion](https://edstem.org/) - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants__: Take a few minutes to explore the datasets we'll explore in the problem set. You can specify the number of training and test examples to train and test your SVM.\n",
    "* __Task 2: Linear SVM classification__: In this task, [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `radial basis` kernel. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). We'll use the default values for the $\\gamma$ and $\\nu$ parameters.\n",
    "* __Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM__: In this task, perform a grid search to estimate the best hyperparameters for a kernel SVM using the RBF kernel. We'll estimate the best $\\nu$ parameter in the objective function and the length-scale $\\gamma$ parameter.\n",
    "\n",
    "Tests throughout the notebook (and at the bottom section) help you determine if things are running correctly. Let's go!!! (Don't forget to answer the discussion questions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef21be-0201-4515-89bb-ba8112541d8e",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as external packages, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070be284-e10c-4c83-90bb-4cab39d97ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be56e42-f2dd-4da0-a8df-b1bae63621eb",
   "metadata": {},
   "source": [
    "### Data\n",
    "In this section, we'll load [a dataset from the `LIBSVM` data archive](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) that describes the detection on non-coding RNA sequence that was initially published by:\n",
    "* [Andrew V Uzilov, Joshua M Keegan, and David H Mathews. Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change.\n",
    "BMC Bioinformatics, 7(173), 2006.](https://pubmed.ncbi.nlm.nih.gov/16566836/)\n",
    "\n",
    "\n",
    "Non-coding RNAs (ncRNAs) have many roles in cells. However, detecting novel ncRNAs in biochemical screens is challenging. Accurate computational methods for detecting ncRNAs in sequenced genomes are essential to understanding the roles ncRNAs play in cells. In this dataset, there are:\n",
    "\n",
    "* _What's in the dataset_? There are `59535` training instances in the `training` data; each instance has `8` continuous features and a binary label $y\\in\\left\\{-1,1\\right\\}$. The `test` dataset has `271617` instances (with the same `8` continuous features and a binary label).\n",
    "\n",
    "We begin by loading the `training` and `test` datasets. The [`LIBSVM` library authors](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) have developed these subsets. However, we'll need to preprocess both the `training` and `test` sets. Before we do this, we'll set some constants. Please look at the comment next to the constant for a definition of what it is, units, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee4e127-97af-42d7-bd51-99e8897aa76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_examples = nothing; # TODO: Set a value; has to be even, less than the 59535. *Warning* the larger, the slower this will run\n",
    "number_of_test_examples = nothing; # TODO Set a value; has to be even 271617. *Warning* the larger, the slower this will run.\n",
    "number_of_features = 8; # there are eight continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a38761-a24e-45a9-b02d-4fde1fb51963",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see how we preprocessed the `training` dataset. We have [z-score centered](https://en.wikipedia.org/wiki/Standard_score) the training data and combined it into an array where each row is a training instance, while the first `1:number_of_features` columns hold the features. The last column has the label. \n",
    "\n",
    "We store the training data in the `training::Array{Float64,2}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4099b294-ce46-414c-98b4-69ea85e3743a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching /(::Nothing, ::Int64)\nThe function `/` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  /(\u001b[91m::Missing\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:123\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::P\u001b[39m, ::S) where {S<:Number, T, X, P<:Polynomials.FactoredPolynomial{T, X}}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mPolynomials\u001b[39m \u001b[90m~/.julia/packages/Polynomials/MS0TY/src/polynomials/\u001b[39m\u001b[90m\u001b[4mfactored_polynomial.jl:318\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::ChainRulesCore.NotImplemented\u001b[39m, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mChainRulesCore\u001b[39m \u001b[90m~/.julia/packages/ChainRulesCore/U6wNx/src/tangent_types/\u001b[39m\u001b[90m\u001b[4mnotimplemented.jl:42\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching /(::Nothing, ::Int64)\nThe function `/` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  /(\u001b[91m::Missing\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:123\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::P\u001b[39m, ::S) where {S<:Number, T, X, P<:Polynomials.FactoredPolynomial{T, X}}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mPolynomials\u001b[39m \u001b[90m~/.julia/packages/Polynomials/MS0TY/src/polynomials/\u001b[39m\u001b[90m\u001b[4mfactored_polynomial.jl:318\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::ChainRulesCore.NotImplemented\u001b[39m, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mChainRulesCore\u001b[39m \u001b[90m~/.julia/packages/ChainRulesCore/U6wNx/src/tangent_types/\u001b[39m\u001b[90m\u001b[4mnotimplemented.jl:42\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[7]:32"
     ]
    }
   ],
   "source": [
    "training = let\n",
    "\n",
    "    # load the training data -\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-training.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = range(1,stop=number_of_rows,step=1) |> collect |> i-> shuffle!(i);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # Finally, let's make sure the labels are balanced -\n",
    "    yₒ = 1;\n",
    "    is_ok_to_loop = true;\n",
    "    tmp = Set{Array{Float64,1}}();\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ round(number_of_training_examples/2))\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "\n",
    "    yₒ = -1;\n",
    "    is_ok_to_loop = true;\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ number_of_training_examples)\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    D = Array{Float64,2}(undef, number_of_training_examples, (number_of_features + 1));\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        x = pop!(tmp);\n",
    "        for j ∈ 1:(number_of_features + 1)\n",
    "            D[i,j] = x[j];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    D; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd427f-508a-42f0-a15e-0590a3ea3206",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see how we preprocessed the `test` dataset.  We have [z-score centered](https://en.wikipedia.org/wiki/Standard_score) the test data and combined it into an array where each row is a test instance, while the first `1:number_of_features` columns hold the features. The last column has the label.\n",
    "\n",
    "We store the training data in the `test::Array{Float64,2}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93abdbf4-aac4-43c0-ae82-afcf1ffad359",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching /(::Nothing, ::Int64)\nThe function `/` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  /(\u001b[91m::Missing\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:123\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::P\u001b[39m, ::S) where {S<:Number, T, X, P<:Polynomials.FactoredPolynomial{T, X}}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mPolynomials\u001b[39m \u001b[90m~/.julia/packages/Polynomials/MS0TY/src/polynomials/\u001b[39m\u001b[90m\u001b[4mfactored_polynomial.jl:318\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::ChainRulesCore.NotImplemented\u001b[39m, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mChainRulesCore\u001b[39m \u001b[90m~/.julia/packages/ChainRulesCore/U6wNx/src/tangent_types/\u001b[39m\u001b[90m\u001b[4mnotimplemented.jl:42\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching /(::Nothing, ::Int64)\nThe function `/` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  /(\u001b[91m::Missing\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:123\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::P\u001b[39m, ::S) where {S<:Number, T, X, P<:Polynomials.FactoredPolynomial{T, X}}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mPolynomials\u001b[39m \u001b[90m~/.julia/packages/Polynomials/MS0TY/src/polynomials/\u001b[39m\u001b[90m\u001b[4mfactored_polynomial.jl:318\u001b[24m\u001b[39m\n\u001b[0m  /(\u001b[91m::ChainRulesCore.NotImplemented\u001b[39m, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mChainRulesCore\u001b[39m \u001b[90m~/.julia/packages/ChainRulesCore/U6wNx/src/tangent_types/\u001b[39m\u001b[90m\u001b[4mnotimplemented.jl:42\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[9]:31"
     ]
    }
   ],
   "source": [
    "test = let\n",
    "\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-testing.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = range(1,stop=number_of_rows,step=1) |> collect |> i-> shuffle!(i);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # Finally, let's make sure the labels are balanced -\n",
    "    yₒ = 1;\n",
    "    is_ok_to_loop = true;\n",
    "    tmp = Set{Array{Float64,1}}();\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ round(number_of_test_examples/2))\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "\n",
    "    yₒ = -1;\n",
    "    is_ok_to_loop = true;\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ number_of_test_examples)\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    D = Array{Float64,2}(undef, number_of_test_examples, (number_of_features + 1));\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        x = pop!(tmp);\n",
    "        for j ∈ 1:(number_of_features + 1)\n",
    "            D[i,j] = x[j];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    D; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ff19e-5964-4fc5-90c8-0f0577ba06bc",
   "metadata": {},
   "source": [
    "## Task 2: Classification using an Default RBF-SVM\n",
    "In this task, we [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `radial basis kernel`. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). We'll use the default values for the hyperparameters $\\gamma$ and $\\nu$.\n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) takes an augmented training examples matrix $\\hat{\\mathbf{X}}^{\\top}$ where the examples are on the columns and the features are the rows, and a label vector $\\mathbf{y}\\in\\left\\{-1,1\\right\\}$.\n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns a [model instance](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) that holds the trained data and a bunch of other data associated with the problem.\n",
    "* __Hmmm__: One of the (super) interesting optional arguments [the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) is the `kernel` argument. Check out the documentation to see what kernels are supported! Wow! we get [kernelized SVM capability](https://en.wikipedia.org/wiki/Support_vector_machine#Nonlinear_kernels) right out of the box. _Buy versus build, 99% buy!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c5e427-8dce-47b2-a1d3-51fd7bcfbbed",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[11]:6"
     ]
    }
   ],
   "source": [
    "model = let\n",
    "\n",
    "    model = nothing; # default\n",
    "    \n",
    "    # Setup the data that we are using\n",
    "    D = training; # what dataset are we looking at?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "\n",
    "    # TODO: Uncomment the line below to train the SVM model using the training data \n",
    "    # model = svmtrain(X, y, kernel=LIBSVM.Kernel.RadialBasis, verbose = false, svmtype = LIBSVM.NuSVC, nt = -1); # we are using the LIBSVM\n",
    "\n",
    "    # return\n",
    "    model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a40341-4c8c-4511-8a6f-814182d10735",
   "metadata": {},
   "source": [
    "__Inference__: Now that we have parameters estimated from the `training` data, we can use those parameters on the `test` dataset to see how well the model can differentiate between an actual banknote and a forgery on data it has never seen. We run the classification operation on the (unseen) test data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). \n",
    "* The [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns the predicted label which we store in the `ŷ::Array{Int64,1}` array. We store the actual (correct) label in the `y::Array{Int64,1}` vector.\n",
    "\n",
    "Finally, we compute the confusion matrix. The confusion matrix is a $2\\times{2}$ matrix that contains four entries: true positive (TP), false positive (FP), true negative (TN), and false negative (FN). [Click me for a confusion matrix schematic!](https://github.com/varnerlab/CHEME-5820-Labs-Spring-2025/blob/main/labs/week-3/L3b/figs/Fig-BinaryConfusionMatrix.pdf). Let's compute these four values [using the `confusion(...)` method](src/Compute.jl) and store them in the `CM::Array{Int64,2}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b42d7969-9bfa-4f4f-98fb-ea9443c11eab",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:4"
     ]
    }
   ],
   "source": [
    "ŷ,y,CM = let\n",
    "\n",
    "     # Setup the data that we are using\n",
    "    D = test; # HMMM: If we change test to training what are we calculating?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "    \n",
    "    # TODO: Uncomment the line below to test the SVM model on the other block of the data.\n",
    "    # ŷ, decision_values = svmpredict(model, X);\n",
    "\n",
    "    # TODO: Uncomment the line below to compute the confusion matrix\n",
    "    # CM = confusion(y, ŷ) # call with the SVM test values\n",
    "    \n",
    "    # return -\n",
    "    ŷ,y,CM\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52750870-9c80-4e72-8dfa-6761ba710171",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[14]:1"
     ]
    }
   ],
   "source": [
    "number_of_test_points = length(y);\n",
    "correct_prediction_perceptron = CM[1,1] + CM[2,2];\n",
    "(correct_prediction_perceptron/number_of_test_points) |> f-> println(\"Fraction correct: $(f) Fraction incorrect $(1-f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e2021-5686-473e-8f6b-a4508bb14a31",
   "metadata": {},
   "source": [
    "## Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM\n",
    "In this task, we'll perform a grid search to estimate the best hyperparameters for a kernel SVM using the RBF kernel. We'll estimate the best $\\nu$ parameter in the objective function and the length-scale $\\gamma$ parameter. [A grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search) for kernel SVM parameters $\\nu$ and $\\gamma$ involves systematically exploring combinations of these hyperparameters to find the optimal configuration for model performance. Here's a description of the process:\n",
    "* __Define parameter ranges__. For the $\\nu$ parameter, we use $\\nu\\in[0,1)$ in steps of $\\Delta\\nu$, while for the length scale parameter $\\gamma$, we use $\\gamma\\in\\left\\{2^{-15},2^{-13},\\dots,2^{4}\\right\\}$ where we store the exponents (or values) in the `α::Array{Float64,1}` and `β::Array{Float64,1}` arrays, respectively.\n",
    "* __Model training and evaluation__: For each parameter combination $(\\nu_{i},\\gamma_{j})$, we train an SVM model with an RBF kernel, compute the confusion matrix, and then evaluate the prediction accuracy. We save the accuracy data in the `A::Array{Float64,2}` array, where $a_{ij}\\in\\mathbf{A}$ holds the accuracy values for the parameter combination $(\\nu_{i},\\gamma_{j})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "916a6ac0-a18f-4b0e-9aa5-dda1e0fa7dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:4"
     ]
    }
   ],
   "source": [
    "A, α, β = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "\n",
    "    # setup the grid\n",
    "    α = range(0.1,stop = 0.9, step=0.05) |> collect; # TODO: want to change this? (optional)\n",
    "    β = range(-15,stop = 4, step=2) |> collect; # exponent for γ -\n",
    "    number_of_points_nu = length(α);\n",
    "    number_of_points_gamma = length(β);\n",
    "    accuracy = Array{Float64,2}(undef, number_of_points_nu, number_of_points_gamma);\n",
    "\n",
    "    # main loop\n",
    "    for i ∈ eachindex(α)\n",
    "        ν = α[i];\n",
    "        for j ∈ eachindex(β)\n",
    "            γ = 2.0^β[j];\n",
    "\n",
    "            # TODO: Uncomment below to train the mode in the (nu,γ) values -\n",
    "            # ŷ₂,_ = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "            #    verbose = false, nu = ν, gamma = γ, nt = -1, svmtype = LIBSVM.NuSVC) |> model -> svmpredict(model,X₂);\n",
    "\n",
    "            # how many mistakes?\n",
    "            accuracy[i,j] = confusion(y₂, ŷ₂) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/number_of_test_examples;\n",
    "        end\n",
    "\n",
    "        # write a message -\n",
    "        \"Best value @i = $(i) equals $(maximum(accuracy))\" |> println\n",
    "    end\n",
    "    \n",
    "    accuracy, α, β\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfccd256-16f9-4a9f-a649-f25f161fdb53",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[17]:1"
     ]
    }
   ],
   "source": [
    "Gray.(1 .- A) # fun! More accurate parameter combinations are darker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d95311-3b31-4f5f-97ab-4d4074767a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_I_see_the_accuracy_picture = false; # TODO: update this flag {true | false}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "476dbf34-3f9d-482e-a389-46b0325d6872",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "A # rows are nu, cols are γ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00c9e8-1f2c-4e93-b766-cd6b634ae35d",
   "metadata": {},
   "source": [
    "### What is the best SVM model?\n",
    "Let's find the model with the highest training accuracy. We'll call this the _best model_ and save it in the `best_model::LIBSVM.SVM` variable. First, which element of the accuracy matrix $\\mathbf{A}$ holds the maximum?\n",
    "* We can estimate maximum accuracy element of the matrix $\\mathbf{A}$ [using the `maximum(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.maximum). The `(i,j)` position of the maximum element can be computed using [the `argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax). The [`argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax) returns a cool data structure [called a `CartesianIndex`](https://docs.julialang.org/en/v1/base/arrays/#Base.IteratorsMD.CartesianIndex) which holds the (`row, col`) values of the maximum. This data structure is a way to model collection indices (which seems interesting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7cb67f-dcaa-4fcd-a800-389d8b580625",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[21]:1"
     ]
    }
   ],
   "source": [
    "coordinate = argmax(A)\n",
    "best_accuracy = maximum(A)\n",
    "println(\"Best test accuracy: $(best_accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f19ea-d180-491e-bde0-6092861dac79",
   "metadata": {},
   "source": [
    "Next, get the best parameters and save these in the `ν_best::Float64` and `γ_best::Float64` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab4c8dd4-b872-413b-852c-4f0e578bdfa5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `coordinate` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `coordinate` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[23]:3"
     ]
    }
   ],
   "source": [
    "ν_best, γ_best = let\n",
    "    \n",
    "    ν = coordinate[1] |> i-> α[i]; # Wow! we grab the row (corresponds to ν)\n",
    "    γ = coordinate[2] |> i-> β[i] |> e-> 2.0^e; # Nice! grab the col (corresponds to γ), get the exponent from β, and then compute the value\n",
    "\n",
    "    ν,γ\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db671b-1b5a-4afb-990e-3ce8bd784158",
   "metadata": {},
   "source": [
    "Finally, estimate the `best_model::LIBSVM.SVM`, the best predicted label vector `ŷ_test_best::Array{Int64,1}`, and the actual label vector `y_test::Array{Int64,1}` using the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a16e8e86-49ee-41e9-b935-f8fce18f882e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[25]:4"
     ]
    }
   ],
   "source": [
    "best_model, ŷ_test_best, y_test = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "\n",
    "    # estimate the best model -\n",
    "    best_model = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "                    verbose = false, nu = ν_best, gamma = γ_best, svmtype = LIBSVM.NuSVC)\n",
    "    \n",
    "\n",
    "    # compute the ŷ_best -\n",
    "    ŷ_best, _ = svmpredict(best_model,X₂);\n",
    "\n",
    "    # return -\n",
    "    best_model, ŷ_best, y₂\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da36dd-5158-4179-92db-22685d733c49",
   "metadata": {},
   "source": [
    "Confirm the accuracy of the `best_model::LIBSVM.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81cb4bb2-606f-466f-a8ca-bc03112e9202",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y_test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y_test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[27]:1"
     ]
    }
   ],
   "source": [
    "accuracy_best_confirm = confusion(y_test, ŷ_test_best) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/size(test,1) # impressive!\n",
    "@assert best_accuracy == accuracy_best_confirm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d39bbf-ff27-4ce7-ae75-823b73790cf4",
   "metadata": {},
   "source": [
    "## Discussion questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e51db32-d6c2-4837-974f-1926d8649e9f",
   "metadata": {},
   "source": [
    "__DQ1__: Compute the `training` accuracy (hmmm, how do I do that?) and compare it to the `test` accuracy. Which is larger, and is this what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2717710-e7a6-4800-977f-f7805db6b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ1 (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fd926cc-cef8-4e05-b8e4-6ffe4bc9595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ1 = false;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9d9ff-0d66-454d-a648-56fb0e7b9a8f",
   "metadata": {},
   "source": [
    "__DQ2__: Did the grid search improve the `test` accuracy compared with the default parameters? If not, brainstorm a few ideas about what we could do to improve the `test` accuracy and if so, what can we do to improve further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7d0c2e0-7d0a-403e-8142-319f77e6d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ2 (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8041034c-60a9-49f9-83d4-e7c5aa3579f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ2 = false;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b5684-d658-4827-b69f-04dc7a2c374e",
   "metadata": {},
   "source": [
    "__DQ3__: Hmmm. Smaller `test` sets seem to give better predictions. Many questions. Why might this be the case?\n",
    "For example, are we missing more in a particular direction, or are the `test` data examples that we are missing outliers in some way?  Brainstorm some (cheating?) data engineering strategies to jack up the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "837718aa-dd55-465b-b6de-bf690ea5633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ3 (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d215b6ba-76a7-4bc3-affa-ad740035e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ3 = false;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f306b-bb98-47bc-9a49-a8a8604a4dfa",
   "metadata": {},
   "source": [
    "## Tests\n",
    "In the code block below, we check some values in your notebook and give you feedback on which items are correct or different. `Unhide` the code block below (if you are curious) about how we implemented the tests and what we are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fc01ebf-4100-46f4-ba34-f622a28da650",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup, Prerequisites and Data: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:6\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: number_of_training_examples > 0\n",
      "  MethodError: no method matching isless(::Int64, ::Nothing)\n",
      "  The function `isless` exists, but no method is defined for this combination of argument types.\n",
      "  \n",
      "  \u001b[0mClosest candidates are:\n",
      "  \u001b[0m  isless(\u001b[91m::Missing\u001b[39m, ::Any)\n",
      "  \u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:87\u001b[24m\u001b[39m\n",
      "  \u001b[0m  isless(::Any, \u001b[91m::Missing\u001b[39m)\n",
      "  \u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:88\u001b[24m\u001b[39m\n",
      "  \u001b[0m  isless(::Real, \u001b[91m::Union{StatsBase.PValue, StatsBase.TestStat}\u001b[39m)\n",
      "  \u001b[0m\u001b[90m   @\u001b[39m \u001b[33mStatsBase\u001b[39m \u001b[90m~/.julia/packages/StatsBase/xgoZ5/src/\u001b[39m\u001b[90m\u001b[4mstatmodels.jl:91\u001b[24m\u001b[39m\n",
      "  \u001b[0m  ...\n",
      "  \n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1m<\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mInt64, \u001b[90my\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4moperators.jl:353\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1m>\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mNothing, \u001b[90my\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4moperators.jl:379\u001b[24m\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1meval_test\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mevaluated\u001b[39m::\u001b[0mExpr, \u001b[90mquoted\u001b[39m::\u001b[0mExpr, \u001b[90msource\u001b[39m::\u001b[0mLineNumberNode, \u001b[90mnegate\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[32mTest\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:362\u001b[24m\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:6\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:5\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [8] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [9] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Setup, Prerequisites and Data: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:7\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: number_of_test_examples > 0\n",
      "  MethodError: no method matching isless(::Int64, ::Nothing)\n",
      "  The function `isless` exists, but no method is defined for this combination of argument types.\n",
      "  \n",
      "  \u001b[0mClosest candidates are:\n",
      "  \u001b[0m  isless(\u001b[91m::Missing\u001b[39m, ::Any)\n",
      "  \u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:87\u001b[24m\u001b[39m\n",
      "  \u001b[0m  isless(::Any, \u001b[91m::Missing\u001b[39m)\n",
      "  \u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:88\u001b[24m\u001b[39m\n",
      "  \u001b[0m  isless(::Real, \u001b[91m::Union{StatsBase.PValue, StatsBase.TestStat}\u001b[39m)\n",
      "  \u001b[0m\u001b[90m   @\u001b[39m \u001b[33mStatsBase\u001b[39m \u001b[90m~/.julia/packages/StatsBase/xgoZ5/src/\u001b[39m\u001b[90m\u001b[4mstatmodels.jl:91\u001b[24m\u001b[39m\n",
      "  \u001b[0m  ...\n",
      "  \n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1m<\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mInt64, \u001b[90my\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4moperators.jl:353\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1m>\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mNothing, \u001b[90my\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4moperators.jl:379\u001b[24m\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1meval_test\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mevaluated\u001b[39m::\u001b[0mExpr, \u001b[90mquoted\u001b[39m::\u001b[0mExpr, \u001b[90msource\u001b[39m::\u001b[0mLineNumberNode, \u001b[90mnegate\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[32mTest\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:362\u001b[24m\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:7\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:5\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [8] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [9] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Setup, Prerequisites and Data: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:8\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: size(training, 1) == number_of_training_examples\n",
      "  UndefVarError: `training` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:8\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:5\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Setup, Prerequisites and Data: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:9\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: size(test, 1) == number_of_test_examples\n",
      "  UndefVarError: `test` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Hint: a global variable of this name also exists in Pkg.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:9\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:5\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Default RBF-Kernel: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:13\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isnothing(model) == false\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:13\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:13\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Default RBF-Kernel: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:14\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isnothing(CM) == false\n",
      "  UndefVarError: `CM` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:14\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:13\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Grid Search: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:18\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isempty(A) == false\n",
      "  UndefVarError: `A` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:18\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:18\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Grid Search: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:19\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isnothing(best_model) == false\n",
      "  UndefVarError: `best_model` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:19\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:18\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Grid Search: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:20\u001b[22m\n",
      "  Expression: do_I_see_the_accuracy_picture == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:679\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:20\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:18\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Grid Search: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:21\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isnothing(ŷ_test_best) == false\n",
      "  UndefVarError: `ŷ_test_best` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:21\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:18\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Grid Search: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:22\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isnothing(y_test) == false\n",
      "  UndefVarError: `y_test` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "   [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:676\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:22\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:18\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Discussion questions: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:26\u001b[22m\n",
      "  Expression: did_I_answer_DQ1 == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:679\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:26\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:26\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Discussion questions: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:27\u001b[22m\n",
      "  Expression: did_I_answer_DQ2 == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:679\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:27\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:26\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "Discussion questions: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[39]:28\u001b[22m\n",
      "  Expression: did_I_answer_DQ3 == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:679\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:28\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:26\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1704\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[39]:4\u001b[24m\u001b[39m\n",
      "\u001b[0m\u001b[1mTest Summary:                       | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[91m\u001b[1mFail  \u001b[22m\u001b[39m\u001b[91m\u001b[1mError  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "CHEME 5820 problem set 3 test suite | \u001b[32m   1  \u001b[39m\u001b[91m   4  \u001b[39m\u001b[91m   10  \u001b[39m\u001b[36m   15  \u001b[39m\u001b[0m1.5s\n",
      "  Setup, Prerequisites and Data     | \u001b[32m   1  \u001b[39m\u001b[91m      \u001b[39m\u001b[91m    4  \u001b[39m\u001b[36m    5  \u001b[39m\u001b[0m0.7s\n",
      "  Default RBF-Kernel                | \u001b[32m      \u001b[39m\u001b[91m      \u001b[39m\u001b[91m    2  \u001b[39m\u001b[36m    2  \u001b[39m\u001b[0m0.0s\n",
      "  Grid Search                       | \u001b[32m      \u001b[39m\u001b[91m   1  \u001b[39m\u001b[91m    4  \u001b[39m\u001b[36m    5  \u001b[39m\u001b[0m0.8s\n",
      "  Discussion questions              | \u001b[32m      \u001b[39m\u001b[91m   3  \u001b[39m\u001b[91m       \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.0s\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mSome tests did not pass: 1 passed, 4 failed, 10 errored, 0 broken.\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mSome tests did not pass: 1 passed, 4 failed, 10 errored, 0 broken.\u001b[39m",
      "",
      "Stacktrace:",
      " [1] finish(ts::Test.DefaultTestSet; print_results::Bool)",
      "   @ Test ~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/Test.jl:1258",
      " [2] finish(ts::Test.DefaultTestSet)",
      "   @ Test ~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/Test.jl:1233",
      " [3] macro expansion",
      "   @ ~/.julia/juliaup/julia-1.11.3+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/Test/src/Test.jl:1720 [inlined]",
      " [4] top-level scope",
      "   @ In[39]:4"
     ]
    }
   ],
   "source": [
    "let \n",
    "    @testset verbose = true \"CHEME 5820 problem set 3 test suite\" begin\n",
    "        \n",
    "        @testset \"Setup, Prerequisites and Data\" begin\n",
    "            @test _DID_INCLUDE_FILE_GET_CALLED == true\n",
    "            @test number_of_training_examples > 0\n",
    "            @test number_of_test_examples > 0\n",
    "            @test size(training,1) == number_of_training_examples\n",
    "            @test size(test,1) == number_of_test_examples\n",
    "        end\n",
    "\n",
    "        @testset \"Default RBF-Kernel\" begin\n",
    "            @test isnothing(model) == false\n",
    "            @test isnothing(CM) == false\n",
    "        end\n",
    "\n",
    "        @testset \"Grid Search\" begin\n",
    "            @test isempty(A) == false\n",
    "            @test isnothing(best_model) == false\n",
    "            @test do_I_see_the_accuracy_picture == true\n",
    "            @test isnothing(ŷ_test_best) == false\n",
    "            @test isnothing(y_test) == false\n",
    "        end\n",
    "\n",
    "        @testset \"Discussion questions\" begin\n",
    "            @test did_I_answer_DQ1 == true\n",
    "            @test did_I_answer_DQ2 == true\n",
    "            @test did_I_answer_DQ3 == true\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
