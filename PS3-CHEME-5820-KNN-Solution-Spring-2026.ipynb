{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebe7831",
   "metadata": {},
   "source": [
    "# PS3: Let's Classify RNA data using K-Nearest Neighbors (KNN)\n",
    "In this problem set, we will implement the K-Nearest Neighbors (KNN) algorithm to classify RNA data. \n",
    "\n",
    "> __Learning Objectives:__\n",
    ">\n",
    "> By the end of this problem set, you should be able to:\n",
    "> Three learning objectives here\n",
    "\n",
    "Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cabe961",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "First, we set up the computational environment by including the `Include.jl` file and loading any needed resources.\n",
    "\n",
    "> __Environment Setup with Include.jl__\n",
    ">\n",
    "> The [`include(...)` command](https://docs.julialang.org/en/v1/base/base/#include) evaluates the contents of the input source file, `Include.jl`, in the notebook's global scope. The `Include.jl` file sets paths, loads required external packages, etc. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/).\n",
    "\n",
    "Let's set up our code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9ee499",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"Include.jl\")); # include the Include.jl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cd62b",
   "metadata": {},
   "source": [
    "In addition to standard Julia libraries, we'll also use [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). Check out [the documentation](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/) for more information on the functions, types, and data used in this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1261c",
   "metadata": {},
   "source": [
    "### Data\n",
    "Let's load [a dataset from the `LIBSVM` data archive](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) that describes the detection of non-coding RNA sequences that was initially published by:\n",
    "* [Andrew V Uzilov, Joshua M Keegan, and David H Mathews. Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change. BMC Bioinformatics, 7(173), 2006.](https://pubmed.ncbi.nlm.nih.gov/16566836/)\n",
    "\n",
    "\n",
    "Non-coding RNAs (ncRNAs) have many roles in cells. However, detecting novel ncRNAs in biochemical screens is challenging. Accurate computational methods for detecting ncRNAs in sequenced genomes are important to understanding the roles ncRNAs play in cells. \n",
    "\n",
    "> __What's in the dataset?__\n",
    "> \n",
    "> In this dataset, there are `59535` training instances in the `training` data; each instance has `8` continuous features and a binary label $y\\in\\left\\{-1,1\\right\\}$. The `test` dataset has `271617` instances (with the same `8` continuous features and a binary label).\n",
    "\n",
    "We begin by loading the `training` and `test` datasets. The [`LIBSVM` library authors](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) have developed these subsets. \n",
    "\n",
    "However, we'll need to preprocess both the `training` and `test` sets. Before we do this, we'll set some constants. Please look at the comment next to the constant for a definition of what it is, units, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0241898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 8; # there are eight continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f750f3",
   "metadata": {},
   "source": [
    "In the code block below we preprocess the `training` dataset. We have [z-score centered](https://en.wikipedia.org/wiki/Standard_score) the training data and combined it into an array where each row is a training instance, while the first `1:number_of_features` columns hold the features. The last column has the label. \n",
    "\n",
    "We store the training data in the `training::Array{NamedTuple,1}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033a7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = let\n",
    "\n",
    "    # load the training data -\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-training.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = randperm(number_of_rows);\n",
    "    training_data = Array{NamedTuple,1}(undef, number_of_rows);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # package the data into an array of named tuples -\n",
    "    for i ∈ 1:number_of_rows\n",
    "        features = X̂[i,1:number_of_features];\n",
    "        label = X̂[i,end];\n",
    "        training_data[i] = (x = features, y = (label |> Int ));\n",
    "    end\n",
    "\n",
    "    training_data; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd5436",
   "metadata": {},
   "source": [
    "Next, we preprocess the `test` dataset.  We [z-score center](https://en.wikipedia.org/wiki/Standard_score) the test data and combined it into an array where each row is a test instance, while the first `1:number_of_features` columns hold the features. The last column has the label.\n",
    "\n",
    "We store the training data in the `test::Array{NamedTuple,1}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b067bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = let\n",
    "\n",
    "    # load the training data -\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-testing.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = randperm(number_of_rows);\n",
    "    test_data = Array{NamedTuple,1}(undef, number_of_rows);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # package the data into an array of named tuples -\n",
    "    for i ∈ 1:number_of_rows\n",
    "        features = X̂[i,1:number_of_features];\n",
    "        label = X̂[i,end];\n",
    "        test_data[i] = (x=features, y = (label |> Int ));\n",
    "    end\n",
    "\n",
    "    test_data; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f38bb0",
   "metadata": {},
   "source": [
    "__Are the labels in the training dataset balanced?__ Since we are using a KNN classifier, it is important to have balanced labels in the training dataset. If the labels are imbalanced in our reference dataset, the KNN classifier may be biased towards the majority class, which can lead to poor performance on the minority class. We can check for label balance by looking at the distribution of labels in the training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224314eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of positive labels in the training dataset: 0.3333333333333333\n",
      "Fraction of negative labels in the training dataset: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "let \n",
    "\n",
    "    # initialize -\n",
    "    D = training; # specify what data set we are working with\n",
    "    number_of_training_examples = length(D); # how many examples are in the training dataset?\n",
    "\n",
    "    # Fancy! Let's use a list comprehension to count the number of positive and negative labels in the training dataset. The `sum()` function will sum up the number of times the condition is true for each example in the training dataset.\n",
    "    count_positive_labels = sum(D[i].y == 1 for i ∈ 1:number_of_training_examples); # how many positive labels are in the training dataset?\n",
    "    count_negative_labels = sum(D[i].y == -1 for i ∈ 1:number_of_training_examples); # how many negative labels are in the training dataset?\n",
    "    \n",
    "    # print the results (fraction of positive and negative labels in the training dataset)\n",
    "    println(\"Fraction of positive labels in the training dataset: \", count_positive_labels / number_of_training_examples);\n",
    "    println(\"Fraction of negative labels in the training dataset: \", count_negative_labels / number_of_training_examples);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ae6de",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfa5a2",
   "metadata": {},
   "source": [
    "## Task 2: Let's look at our KNN Classifier\n",
    "In this task, we will build and evaluate the KNN classifier that we will be using to make predictions on the test dataset. We'll build [a `MyWeightedKernelizedKNNClassificationModel` model](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/binaryclassification/#VLDataScienceMachineLearningPackage.MyWeightedKernelizedKNNClassificationModel) using the `training` dataset as the reference data.\n",
    "\n",
    "Let's build a kernel function $k:\\mathbb{R}^{m}\\times\\mathbb{R}^{m}\\to\\mathbb{R}$ to measure similarity. For now, let's make up our own kernel function, and save this function in the `k(x,y)::Function` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa8a5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k(x,y,γ) = exp(-γ * norm(x-y,2)^2) # RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56aaf7",
   "metadata": {},
   "source": [
    "#### Check: Are we using a valid Kernel function?\n",
    "Let's check to see if the distance (similarity) metric we built is a valid kernel function.\n",
    "\n",
    "> __Condition:__\n",
    ">\n",
    "> A function $k:\\mathbb{R}^{m}\\times\\mathbb{R}^{m}\\to\\mathbb{R}$ is a _valid kernel function_ if and only if the kernel matrix $\\mathbf{K}\\in\\mathbb{R}^{n\\times{n}}$ is positive (semi)definite for all possible choices of the data vectors $\\mathbf{v}_i$, where $K_{ij} = k(\\mathbf{v}_i, \\mathbf{v}_j)$. If $\\mathbf{K}$ is positive (semi)definite, then for any real-valued vector $\\mathbf{x} \\in \\mathbb{R}^n$, the kernel matrix $\\mathbf{K}$ must satisfy $\\mathbf{x}^{\\top}\\mathbf{K}\\mathbf{x} \\geq 0$. \n",
    "\n",
    "Let's compute the kernel matrix `KM::Array{Float64,2}` for a data matrix `X::Array{Float64,2}` using the distance/kernel function `k(x,y)::Function` we built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dfa6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KM = let\n",
    "\n",
    "    D = training; # specify what data set we are working with\n",
    "    number_of_training_examples = 1000; # how many examples are in the training dataset (we will use only small number examples to compute the kernel matrix for computational efficiency)\n",
    "    number_of_features = D[1].x |> length; # number of features in the dataset\n",
    "    γ = 0.5; # kernel parameter\n",
    "\n",
    "    # fill up the feature matrix -\n",
    "    X = zeros(number_of_training_examples, number_of_features); # initialize a matrix to hold the features\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        X[i,:] = D[i].x; # fill the matrix with the features from the training dataset\n",
    "    end\n",
    "\n",
    "    # fill up the kernel matrix -\n",
    "    K = zeros(number_of_training_examples,number_of_training_examples);\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        vᵢ = X[i,:];\n",
    "        for j ∈ 1:number_of_training_examples\n",
    "            vⱼ = X[j,:];\n",
    "            K[i,j] = k(vᵢ,vⱼ,γ) # compute kernel value\n",
    "        end\n",
    "    end\n",
    "    K\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115937a2",
   "metadata": {},
   "source": [
    "Next, let's check to see if the kernel matrix `K::Array{Float64,2}` is positive (semi)definite by checking if all of its eigenvalues are non-negative.\n",
    "\n",
    "> __Check:__\n",
    ">\n",
    "> For this kernel to be valid, the kernel matrix $\\mathbf{K}$ needs to be positive (semi)definite, i.e., all eigenvalues $\\lambda_i \\geq 0$. We compute the eigenvalues using [`eigvals`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigvals) and verify they are all non-negative using [the `@assert` macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert) in combination with [the `all` function](https://docs.julialang.org/en/v1/base/collections/#Base.all-Tuple%7BAny%7D).\n",
    "\n",
    "Do we blow up? If not, the matrix is PSD for this dataset, which supports using this kernel in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae360c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    λ = eigvals(KM);\n",
    "    @assert all(λ .≥ -1e-10) \"Kernel matrix is not PSD: min eigenvalue = $(minimum(λ))\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1840d7",
   "metadata": {},
   "source": [
    "Ok, so now let's build the KNN classifier model. There are a few design choices to make, such as the number of neighbors to consider (`K`), the kernel function, and any kernel parameters. \n",
    "\n",
    "> __How do we choose the `K` parameter?__\n",
    ">\n",
    "> The choice of `K` can significantly affect KNN performance. A common approach is to use cross-validation to select the optimal value (we will do this in the problem set). For this lab, we choose $K = mC + 1$, where $m \\geq 0$ is an adjustable parameter and $C$ is the number of classes in the training dataset. We can vary `m` to see how it affects the bias-variance tradeoff of the KNN classifier.\n",
    ">\n",
    "> In this context, __bias__ means a systematic error from an oversimplified neighborhood vote, and __variance__ means sensitivity to which training points happen to be in the dataset.\n",
    "> * __Small `K` values:__ The prediction depends only on a few nearby points, creating a complex decision boundary that responds to local data structure. This reduces bias (systematic error from oversimplification), but sensitivity to which training points happen to be in the neighborhood increases variance. A single mislabeled neighbor can shift the prediction.\n",
    "> * __Large `K` values:__ The prediction averages over many neighbors, reducing sensitivity to which specific training examples are sampled. This decreases variance (robustness to changes in training data), but averaging over a larger region can blur fine class distinctions and increase bias from a coarser decision boundary.\n",
    "\n",
    "Can we see this tradeoff in action by varying `K`? Let's test that on the dataset. Next let's consider our second design choice: the kernel width parameter $\\gamma$ in the RBF kernel.\n",
    "\n",
    "> __Gating parameter $\\gamma$:__\n",
    ">\n",
    "> The parameter $\\gamma>0$ controls how quickly similarity decays with squared distance in $k(\\mathbf{x},\\mathbf{y})=\\exp\\left(-\\gamma\\lVert\\mathbf{x}-\\mathbf{y}\\rVert_2^2\\right)$. Larger $\\gamma$ makes the similarity measure more sensitive, so even small-to-moderate $\\lVert\\mathbf{x}-\\mathbf{y}\\rVert_2^2$ values can drive similarity toward zero and emphasize very local neighbors. Smaller $\\gamma$ makes the kernel less sensitive, so even larger squared-distance differences can still produce moderate similarity and allow more distant neighbors to influence the vote.\n",
    "\n",
    "Let's see how varying $\\gamma$ and the number of neighbors `K` affects the performance of our KNN classifier on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92cee9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = let\n",
    "    \n",
    "    # initialize -\n",
    "    D = training; # specify what data set we are working with\n",
    "    number_of_training_examples = size(D,1); # how many examples are in the training dataset?\n",
    "    number_of_features = D[1].x |> length; # number of features in the dataset\n",
    "    γ = 0.50; # kernel parameter\n",
    "    m = 10; # neighborhood size multiple\n",
    "    C = 2; # number of classes\n",
    "\n",
    "    # fill up the feature matrix -\n",
    "    X = zeros(number_of_training_examples, number_of_features); # initialize a matrix to hold the features\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        X[i,:] = D[i].x; # fill the matrix with the features from the training dataset\n",
    "    end\n",
    "\n",
    "    # fill up the label vector -\n",
    "    y = zeros(number_of_training_examples); # initialize a vector to hold the labels\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        y[i] = D[i].y; # fill the vector with the labels from the training dataset\n",
    "    end\n",
    "\n",
    "    # build a model -\n",
    "    model = build(MyWeightedKernelizedKNNClassificationModel, (\n",
    "        K = (m*C+1), # we look at this many points\n",
    "        features = X,\n",
    "        labels = y,\n",
    "        k = (x,y) -> k(x,y,γ), # RBF kernel similarity metric\n",
    "    ));\n",
    "\n",
    "    model; # return the model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b38ed5",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Now that we have defined a kernel function, and built the model, let's use it to classify our data. We use the KNN classifier from [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). \n",
    "\n",
    "> __What is going on in this code block?__\n",
    ">\n",
    "> In the code block below, we:\n",
    "> * Construct [a `MyWeightedKernelizedKNNClassificationModel` model](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/binaryclassification/#VLDataScienceMachineLearningPackage.MyWeightedKernelizedKNNClassificationModel) using [a `build(...)` method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/factory/). The `model` instance holds the data for the problem, i.e., how many neighbors to look at `K`, and the kernel function $k$.\n",
    "> * Next, we pass this `model` instance to [the `classify(...)` method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/binaryclassification/#VLDataScienceMachineLearningPackage.classify) which takes a test feature $\\mathbf{z}$ and the classifier `model` instance and returns the predicted label value $\\hat{y}$ for the test feature vector $\\mathbf{z}$.\n",
    "\n",
    "We return the predicted labels in `ŷ_KNN` and the actual labels in `y_KNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_KNN,y_KNN = let\n",
    "\n",
    "    # Data -\n",
    "    D = test; # what dataset are we working with?\n",
    "    number_of_test_examples = size(D,1);\n",
    "    number_of_features = D[1].x |> length; # number of features in the dataset\n",
    "\n",
    "     # fill up the feature matrix -\n",
    "    X = zeros(number_of_test_examples, number_of_features); # initialize a matrix to hold the features\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        X[i,:] = D[i].x; # fill the matrix with the features from the test dataset\n",
    "    end\n",
    "\n",
    "    # fill up the label vector (actual labels) -\n",
    "    y = zeros(number_of_test_examples); # initialize a vector to hold the labels\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        y[i] = D[i].y; # fill the vector with the labels from the test dataset\n",
    "    end\n",
    "\n",
    "    # process each vector in the test set, compare that to training (reference), and compute the predicted label -\n",
    "    ŷ = zeros(number_of_test_examples);  # initialize some storage for the predicted label\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        z = X[i,:]; # get feature vector for test\n",
    "        ŷ[i] = classify(z,model) # classify the test vector using the training data\n",
    "    end\n",
    " \n",
    "    # return -\n",
    "    ŷ,y\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48d9ace",
   "metadata": {},
   "source": [
    "## Summary\n",
    "One concise summary sentence of the problem set here.\n",
    "\n",
    "> __Key Takeaways:__\n",
    ">\n",
    "> Three key takeaways here\n",
    "\n",
    "One direct, concise conclusion sentence here.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
