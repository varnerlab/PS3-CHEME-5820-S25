{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32fe3c6d-09ea-4c0e-81f7-3c8454d05e77",
   "metadata": {},
   "source": [
    "# PS3: Kernelized Support Vector Machines (kSVMs)\n",
    "In this problem set, we will experiment with a kernel Support Vector Machine (SVM) to classify challenging non-linearly separable datasets taken from the literature. In particular, we'll look at a kernelized version of the $\\nu$-soft-margin support vector machine. If these terms are unfamiliar, [check out the L5c notes](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-5/L5c/docs/Notes.pdf) and the [this review](https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf).\n",
    "\n",
    "### Theory: Support Vector Machine (SVM)\n",
    "Suppose we have dataset $\\mathcal{D} = \\{(\\hat{\\mathbf{x}}_{i}, y_{i}) \\mid i = 1,2,\\dots,n\\}$, where $\\hat{\\mathbf{x}}_i \\in \\mathbb{R}^p$ is an _augmented_ feature vector ($m$ features with additional `1` to model the bias on the end of the vector) and $y_i \\in \\{-1, 1\\}$ is the corresponding class label. The goal of an SVM (for binary classification tasks) is to find the hyperplane $\\mathcal{H}(\\hat{\\mathbf{x}}) = \\{\\hat{\\mathbf{x}} \\mid \\left<\\hat{\\mathbf{x}},\\theta\\right> = 0\\}$ that separates the data points into two classes (those points above the hyperplane, and those points below the hyperplane), where $\\theta \\in \\mathbb{R}^{p}$ ($p=m+1$) is the normal vector to the hyperplane, or the parameters of the model that we need to estimate.\n",
    "\n",
    "#### $\\nu$-Soft margin support vector machine\n",
    "Today, we'll use a variant of the soft-margin support vector machine developed by Scholkopf et al. called the $\\nu$-support vector classifier:\n",
    "* [Scholkopf B, Smola AJ, Williamson RC, Bartlett PL. New support vector algorithms. Neural Comput. 2000 May;12(5):1207-45. doi: 10.1162/089976600300015565. PMID: 10905814.](https://pubmed.ncbi.nlm.nih.gov/10905814/)\n",
    "\n",
    "This approach introduces a new parameter $\\nu\\in(0,1]$, where $\\nu$ approximates the upper bound on the number of training mistakes. It also replaces the cost coefficient $C$\n",
    "with a model of its value.  In this variant, the training problem (for $l$ training examples) is defined as: \n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\theta}\\quad & \\frac{1}{2}\\lVert{\\theta}\\rVert_{2}^{2} -\\nu\\rho+ \\frac{1}{l}\\sum_{i=1}^{n}\\xi_{i}\\\\\n",
    "    \\text{subject to}\\quad & y_{i}\\left<\\phi(\\hat{\\mathbf{x}}_{i}),\\theta\\right> \\geq \\rho - \\xi_{i}\\quad\\forall i\\\\\n",
    "    & \\xi_{i} \\geq 0\\quad\\forall{i}\\quad\\rho\\geq{0}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\xi_{i}$ is a _slack variable_, that quantifies the cost of a classification mistake, and $\\nu\\in(0,1]$ is a user-defined hyperparameter. Notice, that $C\\equiv{1/l}$ in this variant, thus, as $l\\to\\infty$ then $C\\to{0}$. Finally, notice that we are applying the transformation $\\phi:\\mathbb{R}^{p}\\to\\mathbb{R}^{q}$ where $q>p$ to the input feature vector. This is done _implcitly_ when we select a [kernel function](https://en.wikipedia.org/wiki/Kernel_method).\n",
    "\n",
    "### Tasks\n",
    "Before you start, execute the `Run All Cells` command to check if you have any code or setup issues. Code issues, post them [to Ed Discussion](https://edstem.org/) - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants__: Take a few minutes to explore the datasets we'll explore in the problem set. You can specify the number of training and test examples to train and test your SVM.\n",
    "* __Task 2: Linear SVM classification__: In this task, [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `radial basis` kernel. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). We'll use the default values for the $\\gamma$ and $\\nu$ parameters.\n",
    "* __Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM__: In this task, perform a grid search to estimate the best hyperparameters for a kernel SVM using the RBF kernel. We'll estimate the best $\\nu$ parameter in the objective function and the length-scale $\\gamma$ parameter.\n",
    "\n",
    "Tests throughout the notebook (and at the bottom section) help you determine if things are running correctly. Let's go!!! (Don't forget to answer the discussion questions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef21be-0201-4515-89bb-ba8112541d8e",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as external packages, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070be284-e10c-4c83-90bb-4cab39d97ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80] (cache misses: wrong dep version loaded (2), incompatible header (12), dep missing source (4))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling IJuliaExt [2f4121a4-3b3a-5ce6-9c5e-1f2673ce168a] (cache misses: wrong dep version loaded (6), incompatible header (12))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b] (cache misses: wrong dep version loaded (2), incompatible header (16))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling FileIOExt [f5f51d8f-5827-5d2e-939b-192fcd6ec70c] (cache misses: wrong dep version loaded (6), incompatible header (14))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling LIBSVM [b1bec4e5-fd48-53fe-b0cb-9723c09d164b] (cache misses: incompatible header (4))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Images [916415d5-f1e6-5110-898d-aaa5f9f070e0] (cache misses: wrong dep version loaded (4), incompatible header (14))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling DistributionsChainRulesCoreExt [6db1f127-056a-568b-bd49-ae61d42389fa] (cache misses: wrong dep version loaded (4), incompatible header (14))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling SpecialFunctionsExt [499d2952-c3ce-5339-96ee-b197ee6daaa6] (cache misses: wrong dep version loaded (2), incompatible header (18))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling FilePathsBaseTestExt [36f6b4e4-024d-52bd-a01f-148eb20c09de] (cache misses: wrong dep version loaded (4), incompatible header (12))\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be56e42-f2dd-4da0-a8df-b1bae63621eb",
   "metadata": {},
   "source": [
    "### Data\n",
    "In this section, we'll load [a dataset from the `LIBSVM` data archive](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) that describes the detection on non-coding RNA sequence that was initially published by:\n",
    "* [Andrew V Uzilov, Joshua M Keegan, and David H Mathews. Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change.\n",
    "BMC Bioinformatics, 7(173), 2006.](https://pubmed.ncbi.nlm.nih.gov/16566836/)\n",
    "\n",
    "\n",
    "Non-coding RNAs (ncRNAs) have many roles in cells. However, detecting novel ncRNAs in biochemical screens is challenging. Accurate computational methods for detecting ncRNAs in sequenced genomes are essential to understanding the roles ncRNAs play in cells. In this dataset, there are:\n",
    "\n",
    "* _What's in the dataset_? There are `59535` training instances in the `training` data; each instance has `8` continuous features and a binary label $y\\in\\left\\{-1,1\\right\\}$. The `test` dataset has `271617` instances (with the same `8` continuous features and a binary label).\n",
    "\n",
    "We begin by loading the `training` and `test` datasets. The [`LIBSVM` library authors](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) have developed these subsets. However, we'll need to preprocess both the `training` and `test` sets. Before we do this, we'll set some constants. Please look at the comment next to the constant for a definition of what it is, units, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee4e127-97af-42d7-bd51-99e8897aa76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_examples = 10000; # TODO: Set a value; has to be even, less than the 59535. *Warning* the larger, the slower this will run\n",
    "number_of_test_examples = 100; # TODO Set a value; has to be even 271617. *Warning* the larger, the slower this will run.\n",
    "number_of_features = 8; # there are eight continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a38761-a24e-45a9-b02d-4fde1fb51963",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see how we preprocessed the `training` dataset. We have [z-score centered](https://en.wikipedia.org/wiki/Standard_score) the training data and combined it into an array where each row is a training instance, while the first `1:number_of_features` columns hold the features. The last column has the label. \n",
    "\n",
    "We store the training data in the `training::Array{Float64,2}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4099b294-ce46-414c-98b4-69ea85e3743a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "training = let\n",
    "\n",
    "    # load the training data -\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-training.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = range(1,stop=number_of_rows,step=1) |> collect |> i-> shuffle!(i);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # Finally, let's make sure the labels are balanced -\n",
    "    yₒ = 1;\n",
    "    is_ok_to_loop = true;\n",
    "    tmp = Set{Array{Float64,1}}();\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ round(number_of_training_examples/2))\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "\n",
    "    yₒ = -1;\n",
    "    is_ok_to_loop = true;\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ number_of_training_examples)\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    D = Array{Float64,2}(undef, number_of_training_examples, (number_of_features + 1));\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        x = pop!(tmp);\n",
    "        for j ∈ 1:(number_of_features + 1)\n",
    "            D[i,j] = x[j];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    D; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd427f-508a-42f0-a15e-0590a3ea3206",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see how we preprocessed the `test` dataset.  We have [z-score centered](https://en.wikipedia.org/wiki/Standard_score) the test data and combined it into an array where each row is a test instance, while the first `1:number_of_features` columns hold the features. The last column has the label.\n",
    "\n",
    "We store the training data in the `test::Array{Float64,2}` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93abdbf4-aac4-43c0-ae82-afcf1ffad359",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test = let\n",
    "\n",
    "    data = parser(joinpath(_PATH_TO_DATA, \"cod-rna-testing.data\"));\n",
    "    number_of_rows = size(data,1);\n",
    "    data_perm = range(1,stop=number_of_rows,step=1) |> collect |> i-> shuffle!(i);\n",
    "    X = data[data_perm,:];\n",
    "    \n",
    "    # z-score center the data -\n",
    "    μ = mean(X[:,1:number_of_features],dims=1);\n",
    "    σ = std(X[:,1:number_of_features],dims=1);\n",
    "    X̂ = zeros(number_of_rows,number_of_features+1);\n",
    "    for i ∈ 1:number_of_rows\n",
    "        for j ∈ 1:number_of_features\n",
    "            X̂[i,j] = (X[i,j] - μ[j])/(σ[j]);\n",
    "        end\n",
    "        X̂[i,end] = X[i,end]; # get the label\n",
    "    end\n",
    "\n",
    "    # Finally, let's make sure the labels are balanced -\n",
    "    yₒ = 1;\n",
    "    is_ok_to_loop = true;\n",
    "    tmp = Set{Array{Float64,1}}();\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ round(number_of_test_examples/2))\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "\n",
    "    yₒ = -1;\n",
    "    is_ok_to_loop = true;\n",
    "    while (is_ok_to_loop == true)\n",
    "        i = rand(1:number_of_rows); # generate a random index\n",
    "        y = X̂[i,end]\n",
    "        if (y == yₒ)\n",
    "            x = X̂[i,:];\n",
    "            push!(tmp,x);\n",
    "        end\n",
    "\n",
    "        if (length(tmp) ≥ number_of_test_examples)\n",
    "            is_ok_to_loop = false; # stop\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    D = Array{Float64,2}(undef, number_of_test_examples, (number_of_features + 1));\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        x = pop!(tmp);\n",
    "        for j ∈ 1:(number_of_features + 1)\n",
    "            D[i,j] = x[j];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    D; # return scaled - balanced data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ff19e-5964-4fc5-90c8-0f0577ba06bc",
   "metadata": {},
   "source": [
    "## Task 2: Classification using an Default RBF-SVM\n",
    "In this task, we [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `radial basis kernel`. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). We'll use the default values for the hyperparameters $\\gamma$ and $\\nu$.\n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) takes an augmented training examples matrix $\\hat{\\mathbf{X}}^{\\top}$ where the examples are on the columns and the features are the rows, and a label vector $\\mathbf{y}\\in\\left\\{-1,1\\right\\}$.\n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns a [model instance](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) that holds the trained data and a bunch of other data associated with the problem.\n",
    "* __Hmmm__: One of the (super) interesting optional arguments [the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) is the `kernel` argument. Check out the documentation to see what kernels are supported! Wow! we get [kernelized SVM capability](https://en.wikipedia.org/wiki/Support_vector_machine#Nonlinear_kernels) right out of the box. _Buy versus build, 99% buy!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c5e427-8dce-47b2-a1d3-51fd7bcfbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = let\n",
    "\n",
    "    model = nothing; # default\n",
    "    \n",
    "    # Setup the data that we are using\n",
    "    D = training; # what dataset are we looking at?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "\n",
    "    # TODO: Uncomment the line below to train the SVM model using the training data \n",
    "    model = svmtrain(X, y, kernel=LIBSVM.Kernel.RadialBasis, verbose = false, svmtype = LIBSVM.NuSVC, nt = -1); # we are using the LIBSVM\n",
    "\n",
    "    # return\n",
    "    model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a40341-4c8c-4511-8a6f-814182d10735",
   "metadata": {},
   "source": [
    "__Inference__: Now that we have parameters estimated from the `training` data, we can use those parameters on the `test` dataset to see how well the model can differentiate between an actual banknote and a forgery on data it has never seen. We run the classification operation on the (unseen) test data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). \n",
    "* The [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns the predicted label which we store in the `ŷ::Array{Int64,1}` array. We store the actual (correct) label in the `y::Array{Int64,1}` vector.\n",
    "\n",
    "Finally, we compute the confusion matrix. The confusion matrix is a $2\\times{2}$ matrix that contains four entries: true positive (TP), false positive (FP), true negative (TN), and false negative (FN). [Click me for a confusion matrix schematic!](https://github.com/varnerlab/CHEME-5820-Labs-Spring-2025/blob/main/labs/week-3/L3b/figs/Fig-BinaryConfusionMatrix.pdf). Let's compute these four values [using the `confusion(...)` method](src/Compute.jl) and store them in the `CM::Array{Int64,2}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b42d7969-9bfa-4f4f-98fb-ea9443c11eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ,y,CM = let\n",
    "\n",
    "    # Setup the data that we are using\n",
    "    D = test; # HMMM: If we change test to training what are we calculating?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "    \n",
    "    # TODO: Uncomment the line below to test the SVM model on the other block of the data.\n",
    "    ŷ, decision_values = svmpredict(model, X);\n",
    "\n",
    "    # compute the confusion matrix\n",
    "    CM = confusion(y, ŷ) # call with the SVM test values\n",
    "    \n",
    "    # return -\n",
    "    ŷ,y,CM\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52750870-9c80-4e72-8dfa-6761ba710171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction correct: 0.45 Fraction incorrect 0.55\n"
     ]
    }
   ],
   "source": [
    "number_of_test_points = length(y);\n",
    "correct_prediction_perceptron = CM[1,1] + CM[2,2];\n",
    "(correct_prediction_perceptron/number_of_test_points) |> f-> println(\"Fraction correct: $(f) Fraction incorrect $(1-f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e2021-5686-473e-8f6b-a4508bb14a31",
   "metadata": {},
   "source": [
    "## Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM\n",
    "In this task, we'll perform a grid search to estimate the best hyperparameters for a kernel SVM using the RBF kernel. We'll estimate the best $\\nu$ parameter in the objective function and the length-scale $\\gamma$ parameter. [A grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search) for kernel SVM parameters $\\nu$ and $\\gamma$ involves systematically exploring combinations of these hyperparameters to find the optimal configuration for model performance. Here's a description of the process:\n",
    "* __Define parameter ranges__. For the $\\nu$ parameter, we use $\\nu\\in[0,1)$ in steps of $\\Delta\\nu$, while for the length scale parameter $\\gamma$, we use $\\gamma\\in\\left\\{2^{-15},2^{-13},\\dots,2^{4}\\right\\}$ where we store the exponents (or values) in the `α::Array{Float64,1}` and `β::Array{Float64,1}` arrays, respectively.\n",
    "* __Model training and evaluation__: For each parameter combination $(\\nu_{i},\\gamma_{j})$, we train an SVM model with an RBF kernel, compute the confusion matrix, and then evaluate the prediction accuracy. We save the accuracy data in the `A::Array{Float64,2}` array, where $a_{ij}\\in\\mathbf{A}$ holds the accuracy values for the parameter combination $(\\nu_{i},\\gamma_{j})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "916a6ac0-a18f-4b0e-9aa5-dda1e0fa7dd0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value @i = 1 equals 76.0\n",
      "Best value @i = 2 equals 76.0\n",
      "Best value @i = 3 equals 76.0\n",
      "Best value @i = 4 equals 76.0\n",
      "Best value @i = 5 equals 76.0\n",
      "Best value @i = 6 equals 76.0\n",
      "Best value @i = 7 equals 76.0\n",
      "Best value @i = 8 equals 76.0\n",
      "Best value @i = 9 equals 76.0\n",
      "Best value @i = 10 equals 76.0\n",
      "Best value @i = 11 equals 76.0\n",
      "Best value @i = 12 equals 76.0\n",
      "Best value @i = 13 equals 76.0\n",
      "Best value @i = 14 equals 76.0\n",
      "Best value @i = 15 equals 71.0\n",
      "Best value @i = 16 equals 71.0\n",
      "Best value @i = 17 equals 0.61\n"
     ]
    }
   ],
   "source": [
    "A, α, β = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "\n",
    "    # setup the grid\n",
    "    α = range(0.1,stop = 0.9, step=0.05) |> collect; # exponent for nu -\n",
    "    β = range(-15,stop = 4, step=2) |> collect; # exponent for γ -\n",
    "    number_of_points_nu = length(α);\n",
    "    number_of_points_gamma = length(β);\n",
    "    accuracy = Array{Float64,2}(undef, number_of_points_nu, number_of_points_gamma);\n",
    "\n",
    "    # main loop\n",
    "    for i ∈ eachindex(α)\n",
    "        ν = α[i];\n",
    "        for j ∈ eachindex(β)\n",
    "            γ = 2.0^β[j];\n",
    "\n",
    "            # TODO: Uncomment below to train the mode in the (C,γ) values -\n",
    "            ŷ₂,_ = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "                verbose = false, nu = ν, gamma = γ, nt = -1, svmtype = LIBSVM.NuSVC) |> model -> svmpredict(model,X₂);\n",
    "\n",
    "            # how many mistakes?\n",
    "            accuracy[i,j] = confusion(y₂, ŷ₂) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/number_of_test_examples;\n",
    "        end\n",
    "\n",
    "        # write a message -\n",
    "        \"Best value @i = $(i) equals $(maximum(accuracy))\" |> println\n",
    "    end\n",
    "    \n",
    "    accuracy, α, β\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfccd256-16f9-4a9f-a649-f25f161fdb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling PNGFiles [f57f5aa1-a3ce-4bc8-8ab9-96f992907883] (cache misses: wrong dep version loaded (4), incompatible header (16))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFAAAACICAAAAABVFzMzAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAeNJREFUaAWtwcFqE2EAhdGP5hsTokNDqLhxZ1/Rx9VVUQpSGkLDlCHBxXXzb1zdc/xOnIg9MRFHYiXOxJHYEK+ElEmZlEmZlEmZlDkTB+KNWIkzcSFm4kQciZWQMimTMimTMimTMhfiRhyJlViId2IlPhMrIymTMimTMimTMilzR8zEQrwRN+IrMfF/UiZlUiZlUiZlUuaReCJ2xIE4EwuxJ87ERLwTUiZlUiZlUiZlUuYLcU9ciInYEVviidgzuiOkTMqkTMqkTMqkzIWYiAfiRNyIV+KeWBjdCCmTMimTMimTMinzA6MNcSKOxI7YEyuxYSRlUiZlUiZlUiZl3hEvxDPxSFyILXEgfhN7RlImZVImZVImZVLmQhyILXEirsRK3IgrsTKSMimTMimTMimTMvnngXgh9sQzsRJXYmJ0JaRMyqRMyqRMyqTMI3FldCVmYiEmYkdcGEmZlEmZlEmZlEmZJ2ImZmIhJuIn8UjcGG0IKZMyKZMyKZMyKXNHXIiFuBFbYmZ0JfbEmZAyKZMyKZMyKZMyfxE74hvxRDwTn4gzcSRWRlImZVImZVImZVLmzOhCfCS+ED+Ie2LDaENImZRJmZRJmZRJmXeMbsSW+MPoQszExEjKpEzKpEzKpEzK/gJzok2t8SDcpQAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAACICAAAAABVFzMzAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAeNJREFUaAWtwcFqE2EAhdGP5hsTokNDqLhxZ1/Rx9VVUQpSGkLDlCHBxXXzb1zdc/xOnIg9MRFHYiXOxJHYEK+ElEmZlEmZlEmZlDkTB+KNWIkzcSFm4kQciZWQMimTMimTMimTMhfiRhyJlViId2IlPhMrIymTMimTMimTMilzR8zEQrwRN+IrMfF/UiZlUiZlUiZlUuaReCJ2xIE4EwuxJ87ERLwTUiZlUiZlUiZlUuYLcU9ciInYEVviidgzuiOkTMqkTMqkTMqkzIWYiAfiRNyIV+KeWBjdCCmTMimTMimTMinzA6MNcSKOxI7YEyuxYSRlUiZlUiZlUiZl3hEvxDPxSFyILXEgfhN7RlImZVImZVImZVLmQhyILXEirsRK3IgrsTKSMimTMimTMimTMvnngXgh9sQzsRJXYmJ0JaRMyqRMyqRMyqTMI3FldCVmYiEmYkdcGEmZlEmZlEmZlEmZJ2ImZmIhJuIn8UjcGG0IKZMyKZMyKZMyKXNHXIiFuBFbYmZ0JfbEmZAyKZMyKZMyKZMyfxE74hvxRDwTn4gzcSRWRlImZVImZVImZVLmzOhCfCS+ED+Ie2LDaENImZRJmZRJmZRJmXeMbsSW+MPoQszExEjKpEzKpEzKpEzK/gJzok2t8SDcpQAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "17×10 Matrix{Gray{Float64}}:\n",
       " 0.46  0.4   0.44  0.46  0.53  0.51  0.46  0.53  0.54  0.48\n",
       " 0.51  0.52  0.48  0.46  0.48  0.44  0.49  0.47  0.54  0.46\n",
       " 0.48  0.47  0.54  0.52  0.49  0.41  0.42  0.5   0.52  0.46\n",
       " 0.51  0.56  0.53  0.48  0.47  0.52  0.54  0.54  0.54  0.46\n",
       " 0.58  0.47  0.5   0.54  0.49  0.49  0.56  0.51  0.53  0.43\n",
       " 0.51  0.53  0.49  0.56  0.52  0.55  0.45  0.49  0.51  0.44\n",
       " 0.48  0.53  0.57  0.51  0.5   0.46  0.51  0.48  0.49  0.43\n",
       " 0.5   0.53  0.58  0.45  0.52  0.49  0.55  0.49  0.5   0.43\n",
       " 0.51  0.46  0.44  0.58  0.54  0.55  0.61  0.45  0.49  0.43\n",
       " 0.48  0.52  0.55  0.52  0.51  0.49  0.54  0.44  0.47  0.43\n",
       " 0.48  0.6   0.53  0.56  0.47  0.45  0.48  0.46  0.47  0.42\n",
       " 0.55  0.59  0.53  0.55  0.52  0.49  0.51  0.51  0.47  0.42\n",
       " 0.49  0.6   0.58  0.55  0.54  0.39  0.53  0.52  0.47  0.43\n",
       " 0.52  0.56  0.53  0.52  0.55  0.44  0.53  0.51  0.51  0.42\n",
       " 0.42  0.45  0.59  0.48  0.43  0.48  0.48  0.55  0.53  0.42\n",
       " 0.47  0.47  0.55  0.52  0.57  0.43  0.49  0.56  0.55  0.43\n",
       " 0.48  0.48  0.54  0.55  0.49  0.43  0.45  0.54  0.56  0.43"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gray.(1 .- A) # fun! More accurate parameter combinations are darker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d95311-3b31-4f5f-97ab-4d4074767a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_I_see_the_accuracy_picture = true; # TODO: update this flag {true | false}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "476dbf34-3f9d-482e-a389-46b0325d6872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17×10 Matrix{Float64}:\n",
       " 0.54  0.6   0.56  0.54  0.47  0.49  0.54  0.47  0.46  0.52\n",
       " 0.49  0.48  0.52  0.54  0.52  0.56  0.51  0.53  0.46  0.54\n",
       " 0.52  0.53  0.46  0.48  0.51  0.59  0.58  0.5   0.48  0.54\n",
       " 0.49  0.44  0.47  0.52  0.53  0.48  0.46  0.46  0.46  0.54\n",
       " 0.42  0.53  0.5   0.46  0.51  0.51  0.44  0.49  0.47  0.57\n",
       " 0.49  0.47  0.51  0.44  0.48  0.45  0.55  0.51  0.49  0.56\n",
       " 0.52  0.47  0.43  0.49  0.5   0.54  0.49  0.52  0.51  0.57\n",
       " 0.5   0.47  0.42  0.55  0.48  0.51  0.45  0.51  0.5   0.57\n",
       " 0.49  0.54  0.56  0.42  0.46  0.45  0.39  0.55  0.51  0.57\n",
       " 0.52  0.48  0.45  0.48  0.49  0.51  0.46  0.56  0.53  0.57\n",
       " 0.52  0.4   0.47  0.44  0.53  0.55  0.52  0.54  0.53  0.58\n",
       " 0.45  0.41  0.47  0.45  0.48  0.51  0.49  0.49  0.53  0.58\n",
       " 0.51  0.4   0.42  0.45  0.46  0.61  0.47  0.48  0.53  0.57\n",
       " 0.48  0.44  0.47  0.48  0.45  0.56  0.47  0.49  0.49  0.58\n",
       " 0.58  0.55  0.41  0.52  0.57  0.52  0.52  0.45  0.47  0.58\n",
       " 0.53  0.53  0.45  0.48  0.43  0.57  0.51  0.44  0.45  0.57\n",
       " 0.52  0.52  0.46  0.45  0.51  0.57  0.55  0.46  0.44  0.57"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A # rows are nu, cols are γ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00c9e8-1f2c-4e93-b766-cd6b634ae35d",
   "metadata": {},
   "source": [
    "### What is the best SVM model?\n",
    "Let's find the model with the highest training accuracy. We'll call this the _best model_ and save it in the `best_model::LIBSVM.SVM` variable. First, which element of the accuracy matrix $\\mathbf{A}$ holds the maximum?\n",
    "* We can estimate maximum accuracy element of the matrix $\\mathbf{A}$ [using the `maximum(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.maximum). The `(i,j)` position of the maximum element can be computed using [the `argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax). The [`argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax) returns a cool data structure [called a `CartesianIndex`](https://docs.julialang.org/en/v1/base/arrays/#Base.IteratorsMD.CartesianIndex) which holds the (`row, col`) values of the maximum. This data structure is a way to model collection indices (which seems interesting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7cb67f-dcaa-4fcd-a800-389d8b580625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "coordinate = argmax(A)\n",
    "best_accuracy = maximum(A)\n",
    "println(\"Best test accuracy: $(best_accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f19ea-d180-491e-bde0-6092861dac79",
   "metadata": {},
   "source": [
    "Next, get the best parameters and save these in the `ν_best::Float64` and `γ_best::Float64` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab4c8dd4-b872-413b-852c-4f0e578bdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ν_best, γ_best = let\n",
    "    \n",
    "    ν = coordinate[1] |> i-> α[i]; # Wow! we grab the row (corresponds to ν)\n",
    "    γ = coordinate[2] |> i-> β[i] |> e-> 2.0^e; # Nice! grab the col (corresponds to γ), get the exponent from β, and then compute the value\n",
    "\n",
    "    ν,γ\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db671b-1b5a-4afb-990e-3ce8bd784158",
   "metadata": {},
   "source": [
    "Finally, estimate the `best_model::LIBSVM.SVM`, the best predicted label vector `ŷ_test_best::Array{Int64,1}`, and the actual label vector `y_test::Array{Int64,1}` using the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a16e8e86-49ee-41e9-b935-f8fce18f882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, ŷ_test_best, y_test = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "\n",
    "    # estimate the best model -\n",
    "    best_model = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "                    verbose = false, nu = ν_best, gamma = γ_best, svmtype = LIBSVM.NuSVC)\n",
    "    \n",
    "\n",
    "    # compute the ŷ_best -\n",
    "    ŷ_best, _ = svmpredict(best_model,X₂);\n",
    "\n",
    "    # return -\n",
    "    best_model, ŷ_best, y₂\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da36dd-5158-4179-92db-22685d733c49",
   "metadata": {},
   "source": [
    "Confirm the accuracy of the `best_model::LIBSVM.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81cb4bb2-606f-466f-a8ca-bc03112e9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_best_confirm = confusion(y_test, ŷ_test_best) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/size(test,1) # impressive!\n",
    "@assert best_accuracy == accuracy_best_confirm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d39bbf-ff27-4ce7-ae75-823b73790cf4",
   "metadata": {},
   "source": [
    "## Discussion questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e51db32-d6c2-4837-974f-1926d8649e9f",
   "metadata": {},
   "source": [
    "__DQ1__: Compute the `training` accuracy (hmmm, how do I do that?) and compare it to the `test` accuracy. Which is larger, and is this what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2717710-e7a6-4800-977f-f7805db6b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ1 (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c97ab8f3-ddea-43c4-9507-2234e253cdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIBSVM.SVM{Float64, LIBSVM.Kernel.KERNEL}(NuSVC, LIBSVM.Kernel.RadialBasis, nothing, 9, 10000, 2, [1.0, -1.0], Int32[1, 2], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Float64}, Matrix{Float64}}(7410, Int32[3736, 3674], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], [-0.005417253659371857 0.8491818246554698 … -0.7175831522550732 -0.31666012786045616; 1.0360868582888236 -1.142024944334403 … 0.9897440539776912 1.0360868582888236; … ; -0.6145547615228867 0.7432467250972159 … 2.147695864695112 0.699463632217777; 1.0 1.0 … 1.0 1.0], Int32[1, 2, 3, 4, 5, 6, 8, 10, 12, 14  …  9962, 9969, 9973, 9975, 9978, 9984, 9986, 9993, 9998, 10000], LIBSVM.SVMNode[LIBSVM.SVMNode(1, -0.005417253659371857), LIBSVM.SVMNode(1, 0.8491818246554698), LIBSVM.SVMNode(1, -1.1079555707445687), LIBSVM.SVMNode(1, 1.1498740929514326), LIBSVM.SVMNode(1, 0.1159147142495254), LIBSVM.SVMNode(1, 0.5379389504543854), LIBSVM.SVMNode(1, 0.8333559157977874), LIBSVM.SVMNode(1, -2.632518124034626), LIBSVM.SVMNode(1, -0.27973300719253086), LIBSVM.SVMNode(1, 1.0179915191374138)  …  LIBSVM.SVMNode(1, 1.709056205922872), LIBSVM.SVMNode(1, 0.09481350243928241), LIBSVM.SVMNode(1, 0.5168377386441424), LIBSVM.SVMNode(1, 0.010408655198310395), LIBSVM.SVMNode(1, -0.4696439134847179), LIBSVM.SVMNode(1, 0.2741738028263479), LIBSVM.SVMNode(1, 0.8069794010349838), LIBSVM.SVMNode(1, -0.7123078493025125), LIBSVM.SVMNode(1, -0.7175831522550732), LIBSVM.SVMNode(1, -0.31666012786045616)]), 0.0, [8355.208044051116; 2404.9158539082227; … ; -2402.7600457387334; -8506.465448731165;;], Float64[], Float64[], [1.078743259077005], 3, 0.1111111111111111, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_accuracy = let\n",
    "\n",
    "    # Setup the data that we are using\n",
    "    D = training; # HMMM: If we change test to training what are we calculating?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "\n",
    "    # TODO: Uncomment the line below to train the SVM model using the training data \n",
    "    model = svmtrain(X, y, kernel=LIBSVM.Kernel.RadialBasis, verbose = false, svmtype = LIBSVM.NuSVC, nt = -1); # we are using the LIBSVM\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fd926cc-cef8-4e05-b8e4-6ffe4bc9595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ1 = true;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9d9ff-0d66-454d-a648-56fb0e7b9a8f",
   "metadata": {},
   "source": [
    "__DQ2__: Did the grid search improve the `test` accuracy compared with the default parameters? If not, brainstorm a few ideas about what we could do to improve the `test` accuracy and if so, what can we do to improve further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7d0c2e0-7d0a-403e-8142-319f77e6d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ2 (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8041034c-60a9-49f9-83d4-e7c5aa3579f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ2 = true;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b5684-d658-4827-b69f-04dc7a2c374e",
   "metadata": {},
   "source": [
    "__DQ3__: Hmmm. Smaller `test` sets seem to give better predictions. Many questions. Why might this be the case?\n",
    "For example, are we missing more in a particular direction, or are the `test` data examples that we are missing outliers in some way?  Brainstorm some (cheating?) data engineering strategies to jack up the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "837718aa-dd55-465b-b6de-bf690ea5633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ3 (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d215b6ba-76a7-4bc3-affa-ad740035e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ3 = true;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f306b-bb98-47bc-9a49-a8a8604a4dfa",
   "metadata": {},
   "source": [
    "## Tests\n",
    "In the code block below, we check some values in your notebook and give you feedback on which items are correct or different. `Unhide` the code block below (if you are curious) about how we implemented the tests and what we are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fc01ebf-4100-46f4-ba34-f622a28da650",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:                       | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "CHEME 5820 problem set 3 test suite | \u001b[32m  15  \u001b[39m\u001b[36m   15  \u001b[39m\u001b[0m0.3s\n",
      "  Setup, Prerequisites and Data     | \u001b[32m   5  \u001b[39m\u001b[36m    5  \u001b[39m\u001b[0m0.2s\n",
      "  Default RBF-Kernel                | \u001b[32m   2  \u001b[39m\u001b[36m    2  \u001b[39m\u001b[0m0.0s\n",
      "  Grid Search                       | \u001b[32m   5  \u001b[39m\u001b[36m    5  \u001b[39m\u001b[0m0.0s\n",
      "  Discussion questions              | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.0s\n"
     ]
    }
   ],
   "source": [
    "let \n",
    "    @testset verbose = true \"CHEME 5820 problem set 3 test suite\" begin\n",
    "        \n",
    "        @testset \"Setup, Prerequisites and Data\" begin\n",
    "            @test _DID_INCLUDE_FILE_GET_CALLED == true\n",
    "            @test number_of_training_examples > 0\n",
    "            @test number_of_test_examples > 0\n",
    "            @test size(training,1) == number_of_training_examples\n",
    "            @test size(test,1) == number_of_test_examples\n",
    "        end\n",
    "\n",
    "        @testset \"Default RBF-Kernel\" begin\n",
    "            @test isnothing(model) == false\n",
    "            @test isnothing(CM) == false\n",
    "        end\n",
    "\n",
    "        @testset \"Grid Search\" begin\n",
    "            @test isempty(A) == false\n",
    "            @test isnothing(best_model) == false\n",
    "            @test do_I_see_the_accuracy_picture == true\n",
    "            @test isnothing(ŷ_test_best) == false\n",
    "            @test isnothing(y_test) == false\n",
    "        end\n",
    "\n",
    "        @testset \"Discussion questions\" begin\n",
    "            @test did_I_answer_DQ1 == true\n",
    "            @test did_I_answer_DQ2 == true\n",
    "            @test did_I_answer_DQ3 == true\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
